{
  // --- CONFIGURACIÓN DE LOGGING (REGISTROS) ---
  // (Define qué tan "ruidosa" será la consola de la API)
  "Logging": {
    "LogLevel": {
      // Tu configuración: Silenciosa por defecto, solo muestra "Warnings" o peor
      "Default": "Warning",
      // Silencia a Microsoft, excepto si es un "Error" grave
      "Microsoft": "Error",
      // PERO, sí queremos ver los mensajes de arranque (ej. "Now listening on...")
      "Microsoft.Hosting.Lifetime": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },

  // Acepta peticiones de cualquier host (útil para desarrollo)
  "AllowedHosts": "*",

  // --- 1. CADENAS DE CONEXIÓN A BBDD ---
  // (El "Interruptor de 3 Vías" leerá de aquí)
  "ConnectionStrings": {

    // FASE A (Desarrollo): ¡Tu conexión a Docker/WSL! (Puerto 1401)
    // ¡OJO! Has puesto tu contraseña 'sa' aquí.
    // Esto está BIEN para desarrollo local, pero NUNCA subas esto a un repositorio público.
    "LocalSqlServerConnection": "",

    // FASE C (Producción): Vacía por ahora.
    "AzureProductionSqlConnection": ""
  },

  // --- 2. CONFIGURACIÓN DE TOKENS JWT ---
  // (Leído por TokenService y Program.cs)
  "Jwt": {
    // Clave secreta para "firmar" los tokens. Debe ser larga y compleja.
    "Key": "",
    // Quién emite el token (nuestra API)
    "Issuer": "https://visioanalytica.api",
    // Para quién es el token (nuestras Apps)
    "Audience": "https://visioanalytica.apps"
  },

  // --- 3. CONFIGURACIÓN DE GEMINI (API REST) ---
  // (¡Tu sección! Leída por tu GeminiAnalyzer v4.0)
  "Gemini": {
    // ¡DEBES REEMPLAZAR ESTOS VALORES!
    "ApiKey": "", // Tu API Key
    "EndpointTemplate": "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent", // Plantilla de URL para API Key
    "ProjectId": "", // Tu ID de proyecto

    // Configuración de Resiliencia (Leída por tu GeminiAnalyzer)
    "TimeoutSeconds": 30, // Tiempo de espera
    "MaxRetries": 3, // Reintentos
    "InitialBackoffMs": 1000, // Espera inicial

    // Configuración del Modelo (Leída por tu GeminiAnalyzer)
    "Temperature": 0.2, // 0.0 = Robótico, 1.0 = Creativo
    "MaxOutputTokens": 8192 // Límite de "palabras" de la respuesta
  },

  "AiPrompts": {
    // Nota: En JSON, las comillas " dentro del string deben ser escapadas con \"
    "MasterSst": ""
  }
}